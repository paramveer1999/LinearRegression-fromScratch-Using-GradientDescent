{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the libraries and accomodating the data into a pandas dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('winequality-red.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The equations we will be using is: \n",
    "### 1.\n",
    "\n",
    "### \\begin{align} \n",
    "h_{\\theta}(X) & = \\theta_{0} + \\theta_{1}.x_{1} + \\theta_{2}.x_{2} + \\theta_{3}.x_{3} + \\theta_{4}.x_{4} + \\theta_{5}.x_{5} + \\theta_{6}.x_{6} + \\theta_{7}.x_{7} + \\theta_{8}.x_{8} + \\theta_{9}.x_{9} + \\theta_{10}.x_{10} + \\theta_{11}.x_{11}\n",
    "\\end{align}\n",
    "\n",
    "#### where y hat is the predicted value, $θ_{0}$ is the intercept, $θ_{1}$, $θ_{2}$, $θ_{3}$, $θ_{4}$, $θ_{5}$, $θ_{6}$, $θ_{7}$, $θ_{8}$, $θ_{9}$, $θ_{10}$ and $θ_{11}$ are the coefficients and $X_{1}$, $X_{2}$, $X_{3}$, $X_{4}$, $X_{5}$, $X_{6}$, $X_{7}$, $X_{8}$, $X_{9}$, $X_{10}$ and $X_{11}$ are the independent variables. $X_{0}$ will be a column of 1s in the matrix X. \n",
    "\n",
    "### 2.\n",
    "### \\begin{align} \n",
    "\\theta_{j} = \\theta_{j} - \\alpha\\frac{1}{m}\\sum \\limits _{i=1} ^{m}(h_{\\theta}(x^{i}) - y^{i}).(x_{j}^{i})\n",
    "\\end{align}\n",
    "\n",
    "#### where x are the features(Independent variables), y is the target value(dependent variable) and m is the length of training sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the dataframe to an array for train/test split\n",
    "df_to_array = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.4  ,  0.7  ,  0.   , ...,  0.56 ,  9.4  ,  5.   ],\n",
       "       [ 7.8  ,  0.88 ,  0.   , ...,  0.68 ,  9.8  ,  5.   ],\n",
       "       [ 7.8  ,  0.76 ,  0.04 , ...,  0.65 ,  9.8  ,  5.   ],\n",
       "       ...,\n",
       "       [ 6.3  ,  0.51 ,  0.13 , ...,  0.75 , 11.   ,  6.   ],\n",
       "       [ 5.9  ,  0.645,  0.12 , ...,  0.71 , 10.2  ,  5.   ],\n",
       "       [ 6.   ,  0.31 ,  0.47 , ...,  0.66 , 11.   ,  6.   ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking how our array looks\n",
    "df_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling data to make it random before splitting then splitting into 80% training and 20% testing\n",
    "np.random.shuffle(df_to_array)\n",
    "train, test = df_to_array[:1200,:], df_to_array[1200:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.9 ,  0.66,  0.  , ...,  0.58,  9.5 ,  5.  ],\n",
       "       [12.9 ,  0.5 ,  0.55, ...,  0.68, 10.9 ,  6.  ],\n",
       "       [ 7.7 ,  0.51,  0.28, ...,  0.74,  9.2 ,  5.  ],\n",
       "       ...,\n",
       "       [ 7.6 ,  0.54,  0.13, ...,  0.61,  9.4 ,  5.  ],\n",
       "       [ 7.3 ,  0.51,  0.18, ...,  0.73,  9.5 ,  6.  ],\n",
       "       [ 4.6 ,  0.52,  0.15, ...,  0.56, 13.1 ,  4.  ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking our training sample\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.8       ,  0.24      ,  0.54      , ...,  0.54      ,\n",
       "         9.2       ,  5.        ],\n",
       "       [10.3       ,  0.34      ,  0.52      , ...,  0.64      ,\n",
       "         9.4       ,  5.        ],\n",
       "       [ 7.4       ,  0.5       ,  0.47      , ...,  0.57      ,\n",
       "         9.1       ,  5.        ],\n",
       "       ...,\n",
       "       [13.2       ,  0.38      ,  0.55      , ...,  0.54      ,\n",
       "         9.4       ,  5.        ],\n",
       "       [ 6.9       ,  0.84      ,  0.21      , ...,  0.72      ,\n",
       "         9.23333333,  6.        ],\n",
       "       [ 8.2       ,  0.635     ,  0.1       , ...,  0.75      ,\n",
       "        10.9       ,  6.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking our testing sample\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diving split data into X and y for machine learning where X will be for independent variables and y for dependent\n",
    "X_train = train[:,:-1]\n",
    "X_test = test[:,:-1]\n",
    "y_train = train[:,-1]\n",
    "y_test = test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost:           0.5255890695579148 \n",
      "Intercept:      0.03031901565804306 \n",
      "Coefficient 1:  0.1891937283474344 \n",
      "Coefficient 2:  0.010026308551905082 \n",
      "Coefficient 3:  0.005872425557930345 \n",
      "Coefficient 4:  0.0370278668051755 \n",
      "Coefficient 5:  0.0019365229359430477 \n",
      "Coefficient 6:  0.01094310895828418 \n",
      "Coefficient 7: -0.003361344755391783 \n",
      "Coefficient 8:  0.03013849948697474 \n",
      "Coefficient 9:  0.10301818060954375 \n",
      "Coefficient 10: 0.023088136006980654 \n",
      "Coefficient 11: 0.33655895823125587\n"
     ]
    }
   ],
   "source": [
    "#Running gradient descent\n",
    "coef1=0\n",
    "coef2=0\n",
    "coef3=0\n",
    "coef4=0\n",
    "coef5=0\n",
    "coef6=0\n",
    "coef7=0\n",
    "coef8=0\n",
    "coef9=0\n",
    "coef10=0\n",
    "coef11=0\n",
    "intercept=0\n",
    "epochs=1000\n",
    "learning_rate=0.0001\n",
    "n = len(y_train)\n",
    "cost_hist = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    #Cost Function\n",
    "    y_current = ((coef1 * X_train[:,0]) + (coef2 * X_train[:,1]) + \n",
    "                 (coef3 * X_train[:,2]) + (coef4 * X_train[:,3]) + \n",
    "                 (coef5 * X_train[:,4]) + (coef6 * X_train[:,5]) + \n",
    "                 (coef7 * X_train[:,6]) + (coef8 * X_train[:,7]) + \n",
    "                 (coef9 * X_train[:,8]) + (coef10 * X_train[:,9]) + \n",
    "                 (coef11 * X_train[:,10]) + intercept)\n",
    "    #To minimize\n",
    "    cost = sum([data**2 for data in (y_train-y_current)])/n\n",
    "    cost_hist.append(cost)\n",
    "    \n",
    "    #Derivate Calculation\n",
    "    intercept_derivative = -(2/n) * sum(y_train - y_current)\n",
    "    coef1_derivative = -(2/n) * sum(X_train[:,0] * (y_train - y_current))\n",
    "    coef2_derivative = -(2/n) * sum(X_train[:,1] * (y_train - y_current))\n",
    "    coef3_derivative = -(2/n) * sum(X_train[:,2] * (y_train - y_current))\n",
    "    coef4_derivative = -(2/n) * sum(X_train[:,3] * (y_train - y_current))\n",
    "    coef5_derivative = -(2/n) * sum(X_train[:,4] * (y_train - y_current))\n",
    "    coef6_derivative = -(2/n) * sum(X_train[:,5] * (y_train - y_current))\n",
    "    coef7_derivative = -(2/n) * sum(X_train[:,6] * (y_train - y_current))\n",
    "    coef8_derivative = -(2/n) * sum(X_train[:,7] * (y_train - y_current))\n",
    "    coef9_derivative = -(2/n) * sum(X_train[:,8] * (y_train - y_current))\n",
    "    coef10_derivative = -(2/n) * sum(X_train[:,9] * (y_train - y_current))\n",
    "    coef11_derivative = -(2/n) * sum(X_train[:,10] * (y_train - y_current))\n",
    "    \n",
    "    #Fitting derivative into main equation to update coefficients\n",
    "    intercept = intercept - (learning_rate * intercept_derivative)\n",
    "    coef1 = coef1 - (learning_rate * coef1_derivative)\n",
    "    coef2 = coef2 - (learning_rate * coef2_derivative)\n",
    "    coef3 = coef3 - (learning_rate * coef3_derivative)\n",
    "    coef4 = coef4 - (learning_rate * coef4_derivative)\n",
    "    coef5 = coef5 - (learning_rate * coef5_derivative)\n",
    "    coef6 = coef6 - (learning_rate * coef6_derivative)\n",
    "    coef7 = coef7 - (learning_rate * coef7_derivative)\n",
    "    coef8 = coef8 - (learning_rate * coef8_derivative)\n",
    "    coef9 = coef9 - (learning_rate * coef9_derivative)\n",
    "    coef10 = coef10 - (learning_rate * coef10_derivative)\n",
    "    coef11 = coef11 - (learning_rate * coef11_derivative)\n",
    "    \n",
    "print('Cost:          ',cost,'\\nIntercept:     ',intercept,'\\nCoefficient 1: ',coef1,'\\nCoefficient 2: ',coef2,'\\nCoefficient 3: ',coef3,\n",
    "      '\\nCoefficient 4: ',coef4,'\\nCoefficient 5: ',coef5,'\\nCoefficient 6: ',coef6,'\\nCoefficient 7:',coef7,\n",
    "      '\\nCoefficient 8: ',coef8,'\\nCoefficient 9: ',coef9,'\\nCoefficient 10:',coef10,'\\nCoefficient 11:',coef11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the cost function\n",
    "plt.plot(cost_hist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the predicted values\n",
    "predicted_values = []\n",
    "for i in range(0,399):\n",
    "    y_pred = ((coef1 * X_test[i,0]) + (coef2 * X_test[i,1]) + \n",
    "              (coef3 * X_test[i,2]) + (coef4 * X_test[i,3]) + \n",
    "              (coef5 * X_test[i,4]) + (coef6 * X_test[i,5]) + \n",
    "              (coef7 * X_test[i,6]) + (coef8 * X_test[i,7]) + \n",
    "              (coef9 * X_test[i,8]) + (coef10 * X_test[i,9]) + \n",
    "              (coef11 * X_test[i,10]) + intercept)\n",
    "    predicted_values.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\begin{align}\n",
    "J(\\theta) = \\frac{1}{n} \\sum \\limits _{i=1} ^{n} (\\hat{y}_i - y_i)^{2}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "#### Where n is the sample size, y hat is the predicted value and y is the test value. J(θ) is actually the cost function and is also called mean squared error. Minimizing the cost function to predict accurately is the principle behind Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5396043418146855\n"
     ]
    }
   ],
   "source": [
    "#Now to calculate the mean squared error\n",
    "Mean_Squared_Error = (sum((predicted_values-y_test)**2)/399)\n",
    "print(Mean_Squared_Error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
